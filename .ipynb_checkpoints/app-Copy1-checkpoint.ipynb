{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c3ed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask import Flask, request, jsonify\n",
    "# import joblib\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import json\n",
    "# import plotly\n",
    "# import dice_ml\n",
    "# import matplotlib.pyplot as plt\n",
    "# from dice_ml import Data, Model, Dice\n",
    "# from lime.lime_tabular import LimeTabularExplainer\n",
    "# import pred_utils_v1\n",
    "# #from pred_utils_v1 import *\n",
    "# #import fraud_utils\n",
    "# #from fraud_utils import *\n",
    "# import ml_explainability_utils\n",
    "# from ml_explainability_utils import *\n",
    "# from ml_explainability_utils import LIMEModelInterpreter, ModelExplainer, SHAPVisualizer\n",
    "# import os\n",
    "\n",
    "\n",
    "\n",
    "# app = Flask(__name__)\n",
    "\n",
    "# # Load data\n",
    "# X_train_ad, y_train_ad, X_train_smote, y_train_smote, X_train_stomek, y_train_stomek = get_data()\n",
    "\n",
    "\n",
    "# # Load models and data outside of request context for efficiency\n",
    "# try:\n",
    "#     rfc_pipeline = joblib.load('rfc_adasyn_pipeline.pkl')\n",
    "#     gbc_pipeline = joblib.load('gbc_smote_pipeline.pkl')\n",
    "#     mlp_pipeline = joblib.load('mlp_smotetomek_pipeline.pkl')\n",
    "    \n",
    "# except Exception as e:\n",
    "#     app.logger.error(\"Failed to load models or data: \" + str(e))\n",
    "#     # Consider whether to halt the app startup if critical resources fail to load\n",
    "\n",
    "# # Utility function to convert plotly figures to JSON\n",
    "# def convert_plotly_figure_to_json(fig):\n",
    "#     return json.dumps(fig, cls=plotly.utils.PlotlyJSONEncoder)\n",
    "\n",
    "\n",
    "# # Function to select the model and corresponding training data based on name\n",
    "# def choose_model_and_data(model_name):\n",
    "#     if model_name == 'Random Forest':\n",
    "#         pipeline = rfc_pipeline\n",
    "#         X_train = X_train_ad\n",
    "#         y_train = y_train_ad\n",
    "#     elif model_name == 'Gradient Boost':\n",
    "#         pipeline = gbc_pipeline\n",
    "#         X_train = X_train_smote\n",
    "#         y_train = y_train_smote\n",
    "#     elif model_name == 'Neural Network':\n",
    "#         pipeline = mlp_pipeline\n",
    "#         X_train = X_train_stomek\n",
    "#         y_train = y_train_stomek\n",
    "#     else:\n",
    "#         raise ValueError(\"Invalid model name\")\n",
    "#     return pipeline, X_train, y_train\n",
    "\n",
    "\n",
    "# # Function to select the model interpretability technique- Options: LIME, \n",
    "\n",
    "# def choose_model_interpretability(technique_name, interpreter, visualizer, feature_explanations, prediction):\n",
    "#     if technique_name == 'LIME':\n",
    "#         mod_explanation = interpreter.interpret_lime_results(feature_explanations, prediction)\n",
    "#         mod_plot = interpreter.plot_lime_explanation(feature_explanations)\n",
    "#         features_influence = interpreter.calculate_and_print_feature_influence(feature_explanations)\n",
    "#     elif technique_name == 'SHAP':\n",
    "#         mod_explanation = visualizer.shap_feature_influence_percentage()\n",
    "#         mod_plot = visualizer.shap_exp_plot()\n",
    "#         features_influence = visualizer.shap_feature_influence()\n",
    "#     else:\n",
    "#         raise ValueError(\"Invalid technique name\")\n",
    "#     return mod_explanation, mod_plot, features_influence\n",
    "\n",
    "\n",
    "# # Function for analyzing feature interactions\n",
    "\n",
    "# def analyze_model_interactions(model_name, technique_name, explainer):\n",
    "#     # Initialize return variables to None as default\n",
    "#     netwgraph_plot, ax, network_explainer, top_main_effect, top_interaction = None, None, None, None, None\n",
    "    \n",
    "#     if model_name in [\"Random Forest\", \"Gradient Boost\"] and technique_name == \"SHAP\":\n",
    "        \n",
    "#         if model_name == \"Random Forest\":\n",
    "#             netwgraph_plot, ax = explainer.create_network_graph_with_communities()\n",
    "#             network_explainer = networkx_exp()  \n",
    "#             top_main_effect, top_interaction = explainer.features_interaction()\n",
    "#         elif model_name == \"Gradient Boost\":\n",
    "#             netwgraph_plot, ax = explainer.create_network_graph_with_communities_gbc()\n",
    "#             network_explainer = networkx_exp()\n",
    "#             top_main_effect, top_interaction = explainer.features_interaction_gbc()\n",
    "#     else:\n",
    "#         print(f\"For Feature Interactions, Use Random Forest/Gradient Boost Model.\")\n",
    "#         return None, None, None, None, None  \n",
    "\n",
    "#     return netwgraph_plot, ax, network_explainer, top_main_effect, top_interaction\n",
    "\n",
    "# @app.route('/')\n",
    "# def index():\n",
    "#     return render_template_string(\"\"\"\n",
    "#     <html>\n",
    "#         <head>\n",
    "#             <title>FraudSenseXAI</title>\n",
    "#             <style>\n",
    "#                 body {\n",
    "#                     font-family: 'Arial', sans-serif;\n",
    "#                     margin: 0;\n",
    "#                     padding: 0 0 100px; /* Adjust bottom padding */\n",
    "#                     background-color: #f4f4f4;\n",
    "#                     color: #333;\n",
    "#                     line-height: 1.6;\n",
    "#                 }\n",
    "#                 .container {\n",
    "#                     width: 80%;\n",
    "#                     margin: auto;\n",
    "#                     overflow: hidden;\n",
    "#                     padding-bottom: 120px; /* Additional padding to push content up */\n",
    "#                 }\n",
    "#                 h1, h2 {\n",
    "#                     color: #0056b3;\n",
    "#                 }\n",
    "#                 h1 {\n",
    "#                     font-size: 2.5em;\n",
    "#                     margin-bottom: 10px;\n",
    "#                 }\n",
    "#                 h2 {\n",
    "#                     font-size: 1.8em;\n",
    "#                     margin-top: 30px;\n",
    "#                 }\n",
    "#                 p {\n",
    "#                     font-size: 1.1em;\n",
    "#                 }\n",
    "#                 ul {\n",
    "#                     list-style-type: none;\n",
    "#                     padding: 0;\n",
    "#                 }\n",
    "#                 ul li {\n",
    "#                     background: #e9ecef;\n",
    "#                     padding: 10px;\n",
    "#                     margin-bottom: 10px;\n",
    "#                     border-radius: 5px;\n",
    "#                 }\n",
    "#                 ul li strong {\n",
    "#                     color: #007bff;\n",
    "#                 }\n",
    "#                 footer {\n",
    "#                     background-color: #333;\n",
    "#                     color: #fff;\n",
    "#                     text-align: center;\n",
    "#                     padding: 10px;\n",
    "#                     position: fixed;\n",
    "#                     left: 0;\n",
    "#                     bottom: 0;\n",
    "#                     width: 100%;\n",
    "#                 }\n",
    "#             </style>\n",
    "#         </head>\n",
    "#         <body>\n",
    "#             <div class=\"container\">\n",
    "#                 <h1>FraudSenseXAI</h1>\n",
    "#                 <h2>Overview</h2>\n",
    "#                 <p><strong>FraudSenseXAI</strong> is an innovative Machine Learning (ML) and Explainable Artificial Intelligence (XAI) application, developed as a part of an MSc final project by Othniel Obasi. This application is dedicated to detecting and analyzing fraudulent activities, with a strong emphasis on the interpretability and transparency of its AI models.</p>\n",
    "#                 <h2>Key Features</h2>\n",
    "#                 <ul>\n",
    "#                     <li><strong>Robust Fraud Detection:</strong> Utilizes advanced ML techniques to identify fraudulent transactions accurately.</li>\n",
    "#                     <li><strong>Explainable AI Elements:</strong> Employs XAI approaches to provide clear insights into the decision-making processes of the AI.</li>\n",
    "#                     <li><strong>Interactive Web Interface:</strong> Features a user-friendly web application for easy access and interpretation of results.</li>\n",
    "#                     <li><strong>Dynamic Visualizations:</strong> Integrates Plotly for interactive and insightful data visualizations.</li>\n",
    "#                     <li><strong>Applicability Across Sectors:</strong> Suitable for use in finance, e-commerce, digital banking, and other sectors.</li>\n",
    "#                 </ul>\n",
    "#                 <h2>About the Author</h2>\n",
    "#                 <p>This project is an MSc Dissertation on the XAI Application of Fraud Detection, authored by Othniel Obasi. It represents a significant contribution to the field of AI, offering practical solutions and valuable insights for the detection of fraudulent activities using AI. For more information, visit the <a href=\"https://huggingface.co/spaces/Othniel74/XAIFraudSense\" target=\"_blank\">project page</a>  </p>\n",
    "#                 <h2>About the Author</h2>\n",
    "#             </div>\n",
    "#             <footer>\n",
    "#                 <p>FraudSenseXAI Â© 2024</p>\n",
    "#             </footer>\n",
    "#         </body>\n",
    "#     </html>\n",
    "#     \"\"\")\n",
    "\n",
    "\n",
    "# # Endpoint to predict and explain\n",
    "# @app.route('/predict_and_explain', methods=['POST'])\n",
    "# def predict_and_explain():\n",
    "#     try:\n",
    "#         data = request.get_json()\n",
    "#         model_name = data['selected_model']\n",
    "#         technique_name = data['selected_interpretability_method']\n",
    "#         step = data['step']\n",
    "#         transaction_type = data['transaction_type']\n",
    "#         amount = data['amount']\n",
    "#         oldbalanceOrg = data['oldbalanceOrg']\n",
    "\n",
    "#         # Mapping transaction type to integer and preparing input data\n",
    "#         transaction_type_num = 1 if transaction_type in [\"Transfer\", \"Cash Out\", \"Payment\", \"Cash In\"] else 0\n",
    "#         user_data = {\n",
    "#             'step': step,\n",
    "#             'type': transaction_type_num,\n",
    "#             'amount': amount,\n",
    "#             'oldbalanceOrg': oldbalanceOrg,\n",
    "#             'newbalanceOrig': oldbalanceOrg + amount\n",
    "#         }\n",
    "        \n",
    "#         df = pd.DataFrame([user_data])\n",
    "#         live_df = generate_transaction_features(df)\n",
    "#         live_instance = live_df\n",
    "#         # Model selection\n",
    "#         pipeline, X_train, y_train = choose_model_and_data(model_name)\n",
    "#         explainer = ModelExplainer(pipeline, live_df)\n",
    "#         interpreter = LIMEModelInterpreter(pipeline, X_train, live_instance, model_name)\n",
    "#         visualizer = SHAPVisualizer(pipeline, live_instance, X_train)\n",
    "\n",
    "\n",
    "#         # Making prediction\n",
    "#         prediction = pipeline.predict(live_df)[0]\n",
    "#         prediction_text = \"Fraudulent\" if prediction == 1 else \"Not Fraudulent\"\n",
    "        \n",
    "\n",
    "#         # Generate explanations and visualizations\n",
    "#         lime_explanation, prediction = interpreter.limeExplainer_live()\n",
    "#         feature_explanations = interpreter.lime_feature_extraction(lime_explanation)\n",
    "#         mod_explanation,  mod_plot, features_influence = choose_model_interpretability(technique_name, interpreter, visualizer, feature_explanations, prediction)\n",
    "#         netwgraph_plot, ax, network_explainer, top_main_effect, top_interaction = analyze_model_interactions(model_name, technique_name, explainer)\n",
    "\n",
    "#         cf_as_dict, original_instance = cf_explanations(pipeline, X_train, y_train, live_df, model_name, total_CFs=1)\n",
    "#         radial_plot = visualize_counterfactuals_radar_plotly(cf_as_dict, original_instance)\n",
    "#         bar_chart = visualize_counterfactuals_plotly(original_instance, cf_as_dict)\n",
    "#         narrative = explain_counterfactual_percentage(original_instance, cf_as_dict)\n",
    "\n",
    "#         # Convert plotly figures to JSON\n",
    "#         radial_plot_json = convert_plotly_figure_to_json(radial_plot)\n",
    "#         bar_chart_json = convert_plotly_figure_to_json(bar_chart)\n",
    "#         mod_plot_json = convert_plotly_figure_to_json(mod_plot)\n",
    "#         netwgraph_plot_json = convert_plotly_figure_to_json(netwgraph_plot)\n",
    "        \n",
    "        \n",
    "#         return jsonify({\n",
    "#             'prediction_text': prediction_text,\n",
    "#             'model_explanation': mod_explanation,\n",
    "#             'mod_plot': mod_plot_json,\n",
    "#             'features_influence': features_influence,\n",
    "#             'netwgraph_plot':netwgraph_plot_json,\n",
    "#             'network_explainer': network_explainer,\n",
    "#             'top_main_effect': top_main_effect,\n",
    "#             'top_interaction': top_interaction,\n",
    "#             'radial_plot': radial_plot_json,\n",
    "#             'bar_chart': bar_chart_json,\n",
    "#             'narrative': narrative\n",
    "#         })\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         app.logger.error(\"Error in predict_and_explain: \" + str(e))\n",
    "#         return jsonify({'error': 'An error occurred during processing.'}), 500\n",
    "    \n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Set debug to False in a production environment\n",
    "#     debug_mode = os.environ.get(\"DEBUG\", \"False\") == \"True\"\n",
    "#     port = int(os.environ.get(\"PORT\", 5000))\n",
    "#     app.run(host=\"0.0.0.0\", port=port, debug=debug_mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399abef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, render_template_string\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "import numpy as np\n",
    "import json\n",
    "import plotly\n",
    "from plotly.utils import PlotlyJSONEncoder\n",
    "import os\n",
    "import ml_explainability_utils\n",
    "from ml_explainability_utils import *\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers \n",
    "from dice_ml.utils.serialize import DummyDataInterface\n",
    "from dice_ml import Data, Model, Dice\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import fraud_utils\n",
    "from fraud_utils import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "try:\n",
    "    rfc_pipeline = joblib.load('rfc_adasyn_pipeline.pkl')\n",
    "    gbc_pipeline = joblib.load('gbc_smote_pipeline.pkl')\n",
    "    mlp_pipeline = joblib.load('mlp_smotetomek_pipeline.pkl')\n",
    "    # Load data and models\n",
    "    X_train_ad, y_train_ad, X_train_smote, y_train_smote, X_train_stomek, y_train_stomek = get_data()\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    app.logger.error(\"Failed to load models or data: \" + str(e))\n",
    "    \n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "\n",
    "# Utility function to convert plotly figures to JSON\n",
    "def convert_plotly_figure_to_json(fig):\n",
    "    return json.dumps(fig, cls=plotly.utils.PlotlyJSONEncoder)\n",
    "\n",
    "# Function to select the model and corresponding training data based on name\n",
    "def choose_model_and_data(model_name):\n",
    "    if model_name == 'Random Forest':\n",
    "        pipeline = rfc_pipeline\n",
    "        X_train = X_train_ad\n",
    "        y_train = y_train_ad\n",
    "    elif model_name == 'Gradient Boost':\n",
    "        pipeline = gbc_pipeline\n",
    "        X_train = X_train_smote\n",
    "        y_train = y_train_smote\n",
    "    elif model_name == 'Neural Network':\n",
    "        pipeline = mlp_pipeline\n",
    "        X_train = X_train_stomek\n",
    "        y_train = y_train_stomek\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name\")\n",
    "    return pipeline, X_train, y_train\n",
    "\n",
    "\n",
    "# Function to select the model interpretability technique- Options: LIME, \n",
    "def choose_model_interpretability(technique_name, interpreter, visualizer, feature_explanations, prediction):\n",
    "    if technique_name == 'LIME':\n",
    "        mod_explanation = interpreter.interpret_lime_results(feature_explanations, prediction)\n",
    "        mod_plot = interpreter.plot_lime_explanation(feature_explanations)\n",
    "        features_influence = interpreter.calculate_and_print_feature_influence(feature_explanations)\n",
    "    elif technique_name == 'SHAP':\n",
    "        mod_explanation = visualizer.shap_feature_influence_percentage()\n",
    "        mod_plot = visualizer.shap_exp_plot()\n",
    "        features_influence = visualizer.shap_feature_influence()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid technique name\")\n",
    "    return mod_explanation, mod_plot, features_influence\n",
    "\n",
    "        \n",
    "\n",
    "# Endpoint to predict and explain\n",
    "@app.route('/predict_and_explain', methods=['POST'])\n",
    "def predict_and_explain():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        model_name = data['selected_model']\n",
    "        technique_name = data['selected_interpretability_method']\n",
    "        step = data['step']\n",
    "        transaction_type = data['transaction_type']\n",
    "        amount = data['amount']\n",
    "        oldbalanceOrg = data['oldbalanceOrg']\n",
    "\n",
    "        user_data = {\n",
    "            'step': step,\n",
    "            'type': transaction_type,\n",
    "            'amount': amount,\n",
    "            'oldbalanceOrg': oldbalanceOrg,\n",
    "            'newbalanceOrig': oldbalanceOrg + amount\n",
    "        }\n",
    "        df = pd.DataFrame([user_data])\n",
    "        live_df = generate_transaction_features(df)\n",
    "        live_instance =  live_df\n",
    "        \n",
    "        pipeline, X_train, y_train = choose_model_and_data(model_name)\n",
    "        explainer = ModelExplainer(pipeline, live_df)\n",
    "        interpreter = LIMEModelInterpreter(pipeline, X_train, live_instance, model_name)\n",
    "        visualizer = SHAPVisualizer(pipeline, live_instance, X_train)\n",
    "\n",
    "        prediction = pipeline.predict(live_df)[0]\n",
    "        prediction_text = \"Fraudulent\" if prediction == 1 else \"Not Fraudulent\"\n",
    "\n",
    "        lime_explanation, prediction = interpreter.limeExplainer_live()\n",
    "        feature_explanations = interpreter.lime_feature_extraction(lime_explanation)\n",
    "        mod_explanation, mod_plot, features_influence = choose_model_interpretability(technique_name, interpreter, visualizer, feature_explanations, prediction)\n",
    "\n",
    "        cf_as_dict, original_instance = cf_explanations(pipeline, X_train, y_train, live_df, model_name, total_CFs=1)\n",
    "        radial_plot = visualize_counterfactuals_radar_plotly(cf_as_dict, original_instance)\n",
    "        bar_chart = visualize_counterfactuals_plotly(original_instance, cf_as_dict)\n",
    "        narrative = explain_counterfactual_percentage(original_instance, cf_as_dict)\n",
    "\n",
    "        # Convert Plotly figures to JSON\n",
    "        radial_plot_json = json.dumps(radial_plot, cls=PlotlyJSONEncoder)\n",
    "        bar_chart_json = json.dumps(bar_chart, cls=PlotlyJSONEncoder)\n",
    "        mod_plot_json = json.dumps(mod_plot, cls=PlotlyJSONEncoder)\n",
    "\n",
    "        return jsonify({\n",
    "            'prediction_text': prediction_text,\n",
    "            'model_explanation': mod_explanation,\n",
    "            'mod_plot': mod_plot_json,\n",
    "            'features_influence': features_influence,\n",
    "           'radial_plot': radial_plot_json,\n",
    "            'bar_chart': bar_chart_json,\n",
    "            'narrative': narrative\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        app.logger.error(\"Error in predict_and_explain: \" + str(e))\n",
    "        return jsonify({'error': 'An error occurred during processing.'}), 500\n",
    "\n",
    "# Additional routes and functions can be added here as needed\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set debug to False in a production environment\n",
    "    debug_mode = os.environ.get(\"DEBUG\", \"False\") == \"True\"\n",
    "    port = int(os.environ.get(\"PORT\", 5000))\n",
    "    app.run(host=\"0.0.0.0\", port=port, debug=debug_mode)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbce69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fafb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dice_ml\n",
    "from dice_ml.utils import helpers \n",
    "# from flask_cors import CORS\n",
    "from flask import send_file\n",
    "from dice_ml.utils.serialize import DummyDataInterface\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import plotly\n",
    "from dice_ml import Data, Model, Dice\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import pred_utils_v1\n",
    "from pred_utils_v1 import *\n",
    "import fraud_utils\n",
    "from fraud_utils import *\n",
    "import os\n",
    "from flask import Flask, render_template_string\n",
    "import ml_explainability_utils\n",
    "from ml_explainability_utils import *\n",
    "from ml_explainability_utils import LIMEModelInterpreter, ModelExplainer, SHAPVisualizer\n",
    "import base64\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load models and data outside of request context for efficiency\n",
    "try:\n",
    "    rfc_pipeline = joblib.load('rfc_adasyn_pipeline.pkl')\n",
    "    gbc_pipeline = joblib.load('gbc_smote_pipeline.pkl')\n",
    "    mlp_pipeline = joblib.load('mlp_smotetomek_pipeline.pkl')\n",
    "    X_train_ad, y_train_ad, X_train_smote, y_train_smote, X_train_stomek, y_train_stomek = get_data()\n",
    "except Exception as e:\n",
    "    app.logger.error(\"Failed to load models or data: \" + str(e))\n",
    "    # Consider whether to halt the app startup if critical resources fail to load\n",
    "\n",
    "# Utility function to convert plotly figures to JSON\n",
    "def convert_plotly_figure_to_json(fig):\n",
    "    return json.dumps(fig, cls=plotly.utils.PlotlyJSONEncoder)\n",
    "\n",
    "\n",
    "# Utility function to convert network graph to image\n",
    "def plot_networkx_graph_base64(model_name, technique_name, explainer):\n",
    "    image_path = None\n",
    "    base64_image = None\n",
    "    try:\n",
    "        # Determine the correct graph generation method based on the model and technique\n",
    "        if model_name == \"Random Forest\" and technique_name == \"SHAP\":\n",
    "            image_path = explainer.create_network_graph_with_communities_v1()\n",
    "        elif model_name == \"Gradient Boost\" and technique_name == \"SHAP\":\n",
    "            image_path = explainer.create_network_graph_with_communities_gbc_v1()\n",
    "        \n",
    "        # If an image path was generated, convert it to a base64 string\n",
    "        if image_path:\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "            # Prefix the base64 string with the necessary data URL scheme for direct use in HTML or Gradio interfaces\n",
    "            base64_image = f\"data:image/png;base64,{base64_image}\"\n",
    "\n",
    "    finally:\n",
    "        # Cleanup the image file if it exists\n",
    "        if image_path and os.path.exists(image_path):\n",
    "            os.remove(image_path)\n",
    "    \n",
    "    if base64_image:\n",
    "        return base64_image\n",
    "    else:\n",
    "        # Handle the case where no graph was generated\n",
    "        print(\"Network Graph Not Available.\")\n",
    "        return None\n",
    "            \n",
    "\n",
    "# Function to select the model interpretability technique- Options: LIME, \n",
    "def choose_model_interpretability(technique_name, feature_explanations, prediction):\n",
    "    if technique_name == 'LIME':\n",
    "        model_explanation = interpreter.interpret_lime_results(feature_explanations, prediction)\n",
    "        mod_plot = interpreter.plot_lime_explanation(feature_explanations)\n",
    "        features_influence = interpreter.calculate_and_print_feature_influence(feature_explanations)\n",
    "    elif technique_name == 'SHAP':\n",
    "        model_explanation = visualizer.shap_feature_influence_percentage()\n",
    "        mod_plot = visualizer.shap_exp_plot()\n",
    "        features_influence = visualizer.shap_feature_influence()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid technique name\")\n",
    "    return model_explanation, mod_plot, features_influence\n",
    "\n",
    "\n",
    "# Utility function to analyze model interactions\n",
    "def analyze_model_interactions(model_name, technique_name):\n",
    "    network_explainer, top_main_effect, top_interaction = None, None, None\n",
    "    \n",
    "    if model_name in [\"Random Forest\", \"Gradient Boost\"] and technique_name == \"SHAP\":\n",
    "        try:\n",
    "            if model_name == \"Random Forest\":\n",
    "                network_explainer = networkx_exp()  \n",
    "                top_main_effect, top_interaction = explainer.features_interaction()\n",
    "                \n",
    "            elif model_name == \"Gradient Boost\":\n",
    "                network_explainer = networkx_exp()  \n",
    "                top_main_effect, top_interaction = explainer.features_interaction_gbc()\n",
    "        except Exception as e:\n",
    "            logging.error(\"An error occurred while analyzing model interactions\", exc_info=True)\n",
    "            return None, None, None  \n",
    "    else:\n",
    "        logging.info(\"Feature Interactions Not Available for this Model.\")\n",
    "        return None, None, None  \n",
    "\n",
    "    return network_explainer, top_main_effect, top_interaction\n",
    "\n",
    "\n",
    "# Function to select the model and corresponding training data based on name\n",
    "def choose_model_and_data(model_name):\n",
    "    if model_name == 'Random Forest':\n",
    "        pipeline = rfc_pipeline\n",
    "        X_train = X_train_ad\n",
    "        y_train = y_train_ad\n",
    "    elif model_name == 'Gradient Boost':\n",
    "        pipeline = gbc_pipeline\n",
    "        X_train = X_train_smote\n",
    "        y_train = y_train_smote\n",
    "    elif model_name == 'Neural Network':\n",
    "        pipeline = mlp_pipeline\n",
    "        X_train = X_train_stomek\n",
    "        y_train = y_train_stomek\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name\")\n",
    "    return pipeline, X_train, y_train\n",
    "\n",
    "\n",
    "# Endpoint to predict and explain\n",
    "@app.route('/predict_and_explain', methods=['POST'])\n",
    "def predict_and_explain():\n",
    "    try:\n",
    "        \n",
    "        data = request.get_json()\n",
    "        model_name = data['selected_model']\n",
    "        technique_name = data['selected_interpretability_method']\n",
    "        step = data['step']\n",
    "        transaction_type = data['transaction_type']\n",
    "        amount = data['amount']\n",
    "        oldbalanceOrg = data['oldbalanceOrg']\n",
    "        \n",
    "        \n",
    "\n",
    "        # Mapping transaction type to integer and preparing input data\n",
    "        transaction_type_num = 1 if transaction_type in [\"Transfer\", \"Cash Out\", \"Payment\", \"Cash In\"] else 0\n",
    "        user_data = {\n",
    "            'step': step,\n",
    "            'type': transaction_type_num,\n",
    "            'amount': amount,\n",
    "            'oldbalanceOrg': oldbalanceOrg,\n",
    "            'newbalanceOrig': oldbalanceOrg + amount\n",
    "        }\n",
    "        df = pd.DataFrame([user_data])\n",
    "        live_df = generate_transaction_features(df)\n",
    "\n",
    "        df = pd.DataFrame([user_data])\n",
    "        live_df = generate_transaction_features(df)\n",
    "        live_instance =  live_df\n",
    "        \n",
    "        \n",
    "        # Model selection\n",
    "        pipeline, X_train, y_train = choose_model_and_data(model_name)\n",
    "\n",
    "        # Making prediction\n",
    "        prediction = pipeline.predict(live_df)[0]\n",
    "        prediction_text = \"Fraudulent\" if prediction == 1 else \"Not Fraudulent\"\n",
    " \n",
    "        \n",
    "        explainer = ModelExplainer(pipeline, live_df)\n",
    "        interpreter = LIMEModelInterpreter(pipeline, X_train, live_instance, model_name)\n",
    "        visualizer = SHAPVisualizer(pipeline, live_instance, X_train)\n",
    "       \n",
    "    \n",
    "        lime_explanation, prediction = interpreter.limeExplainer_live()\n",
    "        feature_explanations = interpreter.lime_feature_extraction(lime_explanation)\n",
    "        model_explanation, mod_plot, features_influence = choose_model_interpretability(technique_name, feature_explanations, prediction)\n",
    "        base64_image = plot_networkx_graph_base64(model_name, technique_name, explainer)\n",
    "        network_explainer, top_main_effect, top_interaction = analyze_model_interactions(model_name, technique_name)\n",
    "\n",
    "        # Generate explanations and visualizations\n",
    "        cf_as_dict, original_instance = cf_explanations(pipeline, X_train, y_train, live_df, model_name, total_CFs=1)\n",
    "        lime_explanation = interpret_lime_results(pipeline, X_train, live_df, model_name)\n",
    "        radial_plot = visualize_counterfactuals_radar_plotly_v1(original_instance, cf_as_dict)\n",
    "        bar_chart = visualize_counterfactuals_plotly_v1(original_instance, cf_as_dict)\n",
    "        narrative = explain_counterfactual_percentage(original_instance, cf_as_dict)\n",
    "\n",
    "        # Convert plotly figures to JSON\n",
    "        mod_plot_json = convert_plotly_figure_to_json(mod_plot)       \n",
    "        radial_plot_json = convert_plotly_figure_to_json(radial_plot)\n",
    "        bar_chart_json = convert_plotly_figure_to_json(bar_chart)\n",
    " \n",
    "\n",
    "        return jsonify({\n",
    "            'prediction_text': prediction_text,\n",
    "            'model_explanation': model_explanation,\n",
    "            'features_influence': features_influence,\n",
    "            'lime_explanation': lime_explanation,\n",
    "            'mod_plot': mod_plot_json,            \n",
    "            'network_graph':nbase64_image,\n",
    "            'network_explainer': network_explainer,\n",
    "            'top_main_effect': top_main_effect,\n",
    "            'top_interaction': top_interaction,\n",
    "            'radial_plot': radial_plot_json,            \n",
    "            'bar_chart': bar_chart_json,\n",
    "            'narrative': narrative\n",
    "        })\n",
    "    except Exception as e:\n",
    "        app.logger.error(\"Error in predict_and_explain: \" + str(e))\n",
    "        return jsonify({'error': 'An error occurred during processing.'}), 500\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set debug to False in a production environment\n",
    "    debug_mode = os.environ.get(\"DEBUG\", \"False\") == \"True\"\n",
    "    port = int(os.environ.get(\"PORT\", 5000))\n",
    "    app.run(host=\"0.0.0.0\", port=port, debug=debug_mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4f252c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import dice_ml\n",
    "from dice_ml.utils import helpers \n",
    "from flask import send_file\n",
    "from dice_ml.utils.serialize import DummyDataInterface\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import plotly\n",
    "from dice_ml import Data, Model, Dice\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import pred_utils_v1\n",
    "from pred_utils_v1 import *\n",
    "import fraud_utils\n",
    "from fraud_utils import *\n",
    "import os\n",
    "from flask import Flask, render_template_string\n",
    "import ml_explainability_utils\n",
    "from ml_explainability_utils import *\n",
    "from ml_explainability_utils import LIMEModelInterpreter, ModelExplainer, SHAPVisualizer\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load models and data outside of request context for efficiency\n",
    "try:\n",
    "    rfc_pipeline = joblib.load('rfc_adasyn_pipeline.pkl')\n",
    "    gbc_pipeline = joblib.load('gbc_smote_pipeline.pkl')\n",
    "    mlp_pipeline = joblib.load('mlp_smotetomek_pipeline.pkl')\n",
    "    X_train_ad, y_train_ad, X_train_smote, y_train_smote, X_train_stomek, y_train_stomek = get_data()\n",
    "except Exception as e:\n",
    "    app.logger.error(\"Failed to load models or data: \" + str(e))\n",
    "    # Consider whether to halt the app startup if critical resources fail to load\n",
    "\n",
    "# Utility function to convert plotly figures to JSON\n",
    "def convert_plotly_figure_to_json(fig):\n",
    "    return json.dumps(fig, cls=plotly.utils.PlotlyJSONEncoder)\n",
    "\n",
    "\n",
    "# Utility function to convert network graph to image\n",
    "def plot_networkx_graph(model_name, technique_name, explainer):\n",
    "    # Initialize return variables\n",
    "    network_graph, network_explainer, top_main_effect, top_interaction = None, None, None, None\n",
    "\n",
    "    try:\n",
    "        if model_name == \"Random Forest\" and technique_name == \"SHAP\":\n",
    "            network_graph = explainer.network_graph_interaction_strength()\n",
    "            network_explainer = networkx_exp()\n",
    "            top_main_effect, top_interaction = explainer.features_interaction_v2()\n",
    "\n",
    "        elif model_name == \"Gradient Boost\" and technique_name == \"SHAP\":\n",
    "            network_graph = explainer.network_graph_interaction_strength_gbc()\n",
    "            network_explainer = networkx_exp()\n",
    "            top_main_effect, top_interaction = explainer.features_interaction_gbc_v2()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while generating the network graph: {e}\")\n",
    "  \n",
    "    if network_graph is None:\n",
    "        print(\"Network Graph Not Available.\")\n",
    "\n",
    "    return network_graph, network_explainer, top_main_effect, top_interaction\n",
    "\n",
    "\n",
    "# Function to select the model interpretability technique- Options: LIME, \n",
    "def choose_model_interpretability(technique_name, feature_explanations, interpreter,visualizer, prediction):\n",
    "    if technique_name == 'LIME':\n",
    "        model_explanation = interpreter.interpret_lime_results(feature_explanations, prediction)\n",
    "        mod_plot = interpreter.plot_lime_explanation(feature_explanations)\n",
    "        features_influence = interpreter.calculate_and_print_feature_influence(feature_explanations)\n",
    "    elif technique_name == 'SHAP':\n",
    "        model_explanation = visualizer.shap_feature_influence_percentage()\n",
    "        mod_plot = visualizer.shap_exp_plot()\n",
    "        features_influence = visualizer.shap_feature_influence()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid technique name\")\n",
    "    return model_explanation, mod_plot, features_influence\n",
    "\n",
    "\n",
    "\n",
    "# Function to select the model and corresponding training data based on name\n",
    "def choose_model_and_data(model_name):\n",
    "    if model_name == 'Random Forest':\n",
    "        pipeline = rfc_pipeline\n",
    "        X_train = X_train_ad\n",
    "        y_train = y_train_ad\n",
    "    elif model_name == 'Gradient Boost':\n",
    "        pipeline = gbc_pipeline\n",
    "        X_train = X_train_smote\n",
    "        y_train = y_train_smote\n",
    "    elif model_name == 'Neural Network':\n",
    "        pipeline = mlp_pipeline\n",
    "        X_train = X_train_stomek\n",
    "        y_train = y_train_stomek\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name\")\n",
    "    return pipeline, X_train, y_train\n",
    "\n",
    "\n",
    "# Endpoint to predict and explain\n",
    "@app.route('/predict_and_explain', methods=['POST'])\n",
    "def predict_and_explain():\n",
    "    try:\n",
    "        \n",
    "        data = request.get_json()\n",
    "        model_name = data['selected_model']\n",
    "        technique_name = data['selected_interpretability_method']\n",
    "        step = data['step']\n",
    "        transaction_type = data['transaction_type']\n",
    "        amount = data['amount']\n",
    "        oldbalanceOrg = data['oldbalanceOrg']\n",
    "        \n",
    "        \n",
    "\n",
    "        # Mapping transaction type to integer and preparing input data\n",
    "        transaction_type_num = 1 if transaction_type in [\"Transfer\", \"Cash Out\", \"Payment\", \"Cash In\"] else 0\n",
    "        user_data = {\n",
    "            'step': step,\n",
    "            'type': transaction_type_num,\n",
    "            'amount': amount,\n",
    "            'oldbalanceOrg': oldbalanceOrg,\n",
    "            'newbalanceOrig': oldbalanceOrg + amount\n",
    "        }\n",
    "        df = pd.DataFrame([user_data])\n",
    "        live_df = generate_transaction_features(df)\n",
    "\n",
    "        df = pd.DataFrame([user_data])\n",
    "        live_df = generate_transaction_features(df)\n",
    "        live_instance =  live_df\n",
    "        \n",
    "        \n",
    "        # Model selection\n",
    "        pipeline, X_train, y_train = choose_model_and_data(model_name)\n",
    "        \n",
    "        explainer = ModelExplainer(pipeline, live_df)\n",
    "        interpreter = LIMEModelInterpreter(pipeline, X_train, live_instance, model_name)\n",
    "        visualizer = SHAPVisualizer(pipeline, live_instance, X_train)\n",
    "\n",
    "        # Making prediction\n",
    "        prediction_v1 = pipeline.predict(live_df)[0]\n",
    "        prediction_text = \"Fraudulent Transaction Suspected!\" if prediction_v1 == 1 else \"Not Fraudulent\"\n",
    "       \n",
    "    \n",
    "        lime_explanation, prediction = interpreter.limeExplainer_live()\n",
    "        feature_explanations = interpreter.lime_feature_extraction(lime_explanation)\n",
    "        model_explanation, mod_plot, features_influence = choose_model_interpretability(technique_name, feature_explanations,\n",
    "                                                                                        interpreter,visualizer, prediction)\n",
    "        network_graph, network_explainer, top_main_effect, top_interaction = plot_networkx_graph(model_name, technique_name, \n",
    "                                                                                                 explainer)\n",
    "       \n",
    "\n",
    "        # Generate explanations and visualizations\n",
    "        cf_as_dict, original_instance = cf_explanations(pipeline, X_train, y_train, live_df, model_name, total_CFs=1)\n",
    "        radial_plot = visualize_counterfactuals_radar_plotly_v1(original_instance, cf_as_dict)\n",
    "        bar_chart = visualize_counterfactuals_plotly_v1(original_instance, cf_as_dict)\n",
    "        narrative = explain_counterfactual_percentage(original_instance, cf_as_dict)\n",
    "\n",
    "        # Convert plotly figures to JSON\n",
    "        mod_plot_json = convert_plotly_figure_to_json(mod_plot)\n",
    "        network_graph_json = convert_plotly_figure_to_json(network_graph)\n",
    "        radial_plot_json = convert_plotly_figure_to_json(radial_plot)\n",
    "        bar_chart_json = convert_plotly_figure_to_json(bar_chart)\n",
    " \n",
    "\n",
    "        return jsonify({\n",
    "            'prediction_text': prediction_text,            \n",
    "            'model_explanation': model_explanation,\n",
    "            'mod_plot': mod_plot_json,            \n",
    "            'features_influence': features_influence,\n",
    "            'network_graph':network_graph_json,\n",
    "            'network_explainer': network_explainer,\n",
    "            'top_main_effect': top_main_effect,\n",
    "            'top_interaction': top_interaction,\n",
    "            'radial_plot': radial_plot_json,            \n",
    "            'bar_chart': bar_chart_json,\n",
    "            'narrative': narrative\n",
    "        })\n",
    "    except Exception as e:\n",
    "        app.logger.error(\"Error in predict_and_explain: \" + str(e))\n",
    "        return jsonify({'error': 'An error occurred during processing.'}), 500\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set debug to False in a production environment\n",
    "    debug_mode = os.environ.get(\"DEBUG\", \"False\") == \"True\"\n",
    "    port = int(os.environ.get(\"PORT\", 5000))\n",
    "    app.run(host=\"0.0.0.0\", port=port, debug=debug_mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a910f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edd0c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa008a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
