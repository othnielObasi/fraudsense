{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde821ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers \n",
    "from dice_ml.utils.serialize import DummyDataInterface\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import plotly\n",
    "from dice_ml import Data, Model, Dice\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import pred_utils_v1\n",
    "from pred_utils_v1 import *\n",
    "import fraud_utils\n",
    "from fraud_utils import *\n",
    "import os\n",
    "from flask import Flask, render_template_string\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load models and data outside of request context for efficiency\n",
    "try:\n",
    "    rfc_pipeline = joblib.load('rfc_adasyn_pipeline.pkl')\n",
    "    gbc_pipeline = joblib.load('gbc_smote_pipeline.pkl')\n",
    "    mlp_pipeline = joblib.load('mlp_smotetomek_pipeline.pkl')\n",
    "    X_train_ad, y_train_ad, X_train_smote, y_train_smote, X_train_stomek, y_train_stomek = get_data()\n",
    "except Exception as e:\n",
    "    app.logger.error(\"Failed to load models or data: \" + str(e))\n",
    "    # Consider whether to halt the app startup if critical resources fail to load\n",
    "\n",
    "# Utility function to convert plotly figures to JSON\n",
    "def convert_plotly_figure_to_json(fig):\n",
    "    return json.dumps(fig, cls=plotly.utils.PlotlyJSONEncoder)\n",
    "\n",
    "# Function to select the model and corresponding training data based on name\n",
    "def choose_model_and_data(model_name):\n",
    "    if model_name == 'Random Forest':\n",
    "        pipeline = rfc_pipeline\n",
    "        X_train = X_train_ad\n",
    "        y_train = y_train_ad\n",
    "    elif model_name == 'Gradient Boost':\n",
    "        pipeline = gbc_pipeline\n",
    "        X_train = X_train_smote\n",
    "        y_train = y_train_smote\n",
    "    elif model_name == 'Neural Network':\n",
    "        pipeline = mlp_pipeline\n",
    "        X_train = X_train_stomek\n",
    "        y_train = y_train_stomek\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name\")\n",
    "    return pipeline, X_train, y_train\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template_string(\"\"\"\n",
    "    <html>\n",
    "        <head>\n",
    "            <title>FraudSenseXAI</title>\n",
    "            <style>\n",
    "                body {\n",
    "                    font-family: 'Arial', sans-serif;\n",
    "                    margin: 0;\n",
    "                    padding: 0 0 100px; /* Adjust bottom padding */\n",
    "                    background-color: #f4f4f4;\n",
    "                    color: #333;\n",
    "                    line-height: 1.6;\n",
    "                }\n",
    "                .container {\n",
    "                    width: 80%;\n",
    "                    margin: auto;\n",
    "                    overflow: hidden;\n",
    "                    padding-bottom: 120px; /* Additional padding to push content up */\n",
    "                }\n",
    "                h1, h2 {\n",
    "                    color: #0056b3;\n",
    "                }\n",
    "                h1 {\n",
    "                    font-size: 2.5em;\n",
    "                    margin-bottom: 10px;\n",
    "                }\n",
    "                h2 {\n",
    "                    font-size: 1.8em;\n",
    "                    margin-top: 30px;\n",
    "                }\n",
    "                p {\n",
    "                    font-size: 1.1em;\n",
    "                }\n",
    "                ul {\n",
    "                    list-style-type: none;\n",
    "                    padding: 0;\n",
    "                }\n",
    "                ul li {\n",
    "                    background: #e9ecef;\n",
    "                    padding: 10px;\n",
    "                    margin-bottom: 10px;\n",
    "                    border-radius: 5px;\n",
    "                }\n",
    "                ul li strong {\n",
    "                    color: #007bff;\n",
    "                }\n",
    "                footer {\n",
    "                    background-color: #333;\n",
    "                    color: #fff;\n",
    "                    text-align: center;\n",
    "                    padding: 10px;\n",
    "                    position: fixed;\n",
    "                    left: 0;\n",
    "                    bottom: 0;\n",
    "                    width: 100%;\n",
    "                }\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <div class=\"container\">\n",
    "                <h1>FraudSenseXAI</h1>\n",
    "                <h2>Overview</h2>\n",
    "                <p><strong>FraudSenseXAI</strong> is an innovative Machine Learning (ML) and Explainable Artificial Intelligence (XAI) application, developed as a part of an MSc final project by Othniel Obasi. This application is dedicated to detecting and analyzing fraudulent activities, with a strong emphasis on the interpretability and transparency of its AI models.</p>\n",
    "                <h2>Key Features</h2>\n",
    "                <ul>\n",
    "                    <li><strong>Robust Fraud Detection:</strong> Utilizes advanced ML techniques to identify fraudulent transactions accurately.</li>\n",
    "                    <li><strong>Explainable AI Elements:</strong> Employs XAI approaches to provide clear insights into the decision-making processes of the AI.</li>\n",
    "                    <li><strong>Interactive Web Interface:</strong> Features a user-friendly web application for easy access and interpretation of results.</li>\n",
    "                    <li><strong>Dynamic Visualizations:</strong> Integrates Plotly for interactive and insightful data visualizations.</li>\n",
    "                    <li><strong>Applicability Across Sectors:</strong> Suitable for use in finance, e-commerce, digital banking, and other sectors.</li>\n",
    "                </ul>\n",
    "                <h2>About the Author</h2>\n",
    "                <p>This project is an MSc Dissertation on the XAI Application of Fraud Detection, authored by Othniel Obasi. It represents a significant contribution to the field of AI, offering practical solutions and valuable insights for the detection of fraudulent activities using AI. For more information, visit the <a href=\"https://huggingface.co/spaces/Othniel74/XAIFraudSense\" target=\"_blank\">project page</a>  </p>\n",
    "                <h2>About the Author</h2>\n",
    "            </div>\n",
    "            <footer>\n",
    "                <p>FraudSenseXAI Â© 2024</p>\n",
    "            </footer>\n",
    "        </body>\n",
    "    </html>\n",
    "    \"\"\")\n",
    "\n",
    "# Endpoint to predict and explain\n",
    "@app.route('/predict_and_explain', methods=['POST'])\n",
    "def predict_and_explain():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        model_name = data['selected_model']\n",
    "        step = data['step']\n",
    "        transaction_type = data['transaction_type']\n",
    "        amount = data['amount']\n",
    "        oldbalanceOrg = data['oldbalanceOrg']\n",
    "\n",
    "        # Mapping transaction type to integer and preparing input data\n",
    "        transaction_type_num = 1 if transaction_type in [\"Transfer\", \"Cash Out\", \"Payment\", \"Cash In\"] else 0\n",
    "        user_data = {\n",
    "            'step': step,\n",
    "            'type': transaction_type_num,\n",
    "            'amount': amount,\n",
    "            'oldbalanceOrg': oldbalanceOrg,\n",
    "            'newbalanceOrig': oldbalanceOrg + amount\n",
    "        }\n",
    "        df = pd.DataFrame([user_data])\n",
    "        live_df = generate_transaction_features(df)\n",
    "\n",
    "        # Model selection\n",
    "        pipeline, X_train, y_train = choose_model_and_data(model_name)\n",
    "\n",
    "        # Making prediction\n",
    "        prediction = pipeline.predict(live_df)[0]\n",
    "        prediction_text = \"Fraudulent\" if prediction == 1 else \"Not Fraudulent\"\n",
    "\n",
    "        # Generate explanations and visualizations\n",
    "        cf_as_dict, original_instance = cf_explanations(pipeline, X_train, y_train, live_df, model_name, total_CFs=1)\n",
    "        lime_explanation = interpret_lime_results(pipeline, X_train, live_df, model_name)\n",
    "        radial_plot = visualize_counterfactuals_radar_plotly_v1(original_instance, cf_as_dict)\n",
    "        bar_chart = visualize_counterfactuals_plotly_v1(original_instance, cf_as_dict)\n",
    "        narrative = explain_counterfactual_percentage(original_instance, cf_as_dict)\n",
    "\n",
    "        # Convert plotly figures to JSON\n",
    "        radial_plot_json = convert_plotly_figure_to_json(radial_plot)\n",
    "        bar_chart_json = convert_plotly_figure_to_json(bar_chart)\n",
    "\n",
    "        return jsonify({\n",
    "            'prediction_text': prediction_text,\n",
    "            'lime_explanation': lime_explanation,\n",
    "            'radial_plot': radial_plot_json,\n",
    "            'bar_chart': bar_chart_json,\n",
    "            'narrative': narrative\n",
    "        })\n",
    "    except Exception as e:\n",
    "        app.logger.error(\"Error in predict_and_explain: \" + str(e))\n",
    "        return jsonify({'error': 'An error occurred during processing.'}), 500\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set debug to False in a production environment\n",
    "    debug_mode = os.environ.get(\"DEBUG\", \"False\") == \"True\"\n",
    "    port = int(os.environ.get(\"PORT\", 5000))\n",
    "    app.run(host=\"0.0.0.0\", port=port, debug=debug_mode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1944508",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers \n",
    "from flask_cors import CORS\n",
    "from dice_ml.utils.serialize import DummyDataInterface\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import plotly\n",
    "from dice_ml import Data, Model, Dice\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import pred_utils_v1\n",
    "from pred_utils_v1 import *\n",
    "import fraud_utils\n",
    "from fraud_utils import *\n",
    "import os\n",
    "from flask import Flask, render_template_string\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load models and data outside of request context for efficiency\n",
    "try:\n",
    "    rfc_pipeline = joblib.load('rfc_adasyn_pipeline.pkl')\n",
    "    gbc_pipeline = joblib.load('gbc_smote_pipeline.pkl')\n",
    "    mlp_pipeline = joblib.load('mlp_smotetomek_pipeline.pkl')\n",
    "    X_train_ad, y_train_ad, X_train_smote, y_train_smote, X_train_stomek, y_train_stomek = get_data()\n",
    "except Exception as e:\n",
    "    app.logger.error(\"Failed to load models or data: \" + str(e))\n",
    "    # Consider whether to halt the app startup if critical resources fail to load\n",
    "\n",
    "# Utility function to convert plotly figures to JSON\n",
    "def convert_plotly_figure_to_json(fig):\n",
    "    return json.dumps(fig, cls=plotly.utils.PlotlyJSONEncoder)\n",
    "\n",
    "\n",
    "# Utility function to convert network graph to image\n",
    "def plot_networkx_graph(model_name, technique_name, explainer):    \n",
    "    image_path = None\n",
    "    if model_name in [\"Random Forest\", \"Gradient Boost\"] and technique_name == \"SHAP\":\n",
    "        if model_name == \"Random Forest\":\n",
    "    image_path = explainer.create_network_graph_with_communities_v1()\n",
    "        elif model_name == \"Gradient Boost\":\n",
    "    image_path = explainer.create_network_graph_with_communities_gbc_v1()  \n",
    "    else:\n",
    "        print(f\"Network Graph Not Available.\")\n",
    "        return None  \n",
    "    return send_file(image_path, mimetype='image/png')\n",
    "\n",
    "\n",
    "# Function to select the model interpretability technique- Options: LIME, \n",
    "def choose_model_interpretability(technique_name, interpreter, visualizer, feature_explanations, prediction):\n",
    "    if technique_name == 'LIME':\n",
    "        mod_explanation = interpreter.interpret_lime_results(feature_explanations, prediction)\n",
    "        mod_plot = interpreter.plot_lime_explanation(feature_explanations)\n",
    "        features_influence = interpreter.calculate_and_print_feature_influence(feature_explanations)\n",
    "    elif technique_name == 'SHAP':\n",
    "        mod_explanation = visualizer.shap_feature_influence_percentage()\n",
    "        mod_plot = visualizer.shap_exp_plot()\n",
    "        features_influence = visualizer.shap_feature_influence()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid technique name\")\n",
    "    return mod_explanation, mod_plot, features_influence\n",
    "\n",
    "\n",
    "# Utility function to analyze model interactions\n",
    "def analyze_model_interactions(model_name, technique_name, explainer):\n",
    "    # Initialize return variables to None as default\n",
    "     network_explainer, top_main_effect, top_interaction = None, None, None\n",
    "    \n",
    "    if model_name in [\"Random Forest\", \"Gradient Boost\"] and technique_name == \"SHAP\":\n",
    "        \n",
    "        if model_name == \"Random Forest\":\n",
    "            network_explainer = networkx_exp()  \n",
    "            top_main_effect, top_interaction = explainer.features_interaction()\n",
    "        elif model_name == \"Gradient Boost\":\n",
    "            network_explainer = networkx_exp()\n",
    "            top_main_effect, top_interaction = explainer.features_interaction_gbc()\n",
    "    else:\n",
    "        print(f\"For Feature Interactions Not Availbale for this Model.\")\n",
    "        return None, None, None \n",
    "\n",
    "    return network_explainer, top_main_effect, top_interaction\n",
    "\n",
    "\n",
    "\n",
    "# Function to select the model and corresponding training data based on name\n",
    "def choose_model_and_data(model_name):\n",
    "    if model_name == 'Random Forest':\n",
    "        pipeline = rfc_pipeline\n",
    "        X_train = X_train_ad\n",
    "        y_train = y_train_ad\n",
    "    elif model_name == 'Gradient Boost':\n",
    "        pipeline = gbc_pipeline\n",
    "        X_train = X_train_smote\n",
    "        y_train = y_train_smote\n",
    "    elif model_name == 'Neural Network':\n",
    "        pipeline = mlp_pipeline\n",
    "        X_train = X_train_stomek\n",
    "        y_train = y_train_stomek\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name\")\n",
    "    return pipeline, X_train, y_train\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template_string(\"\"\"\n",
    "    <html>\n",
    "        <head>\n",
    "            <title>FraudSenseXAI</title>\n",
    "            <style>\n",
    "                body {\n",
    "                    font-family: 'Arial', sans-serif;\n",
    "                    margin: 0;\n",
    "                    padding: 0 0 100px; /* Adjust bottom padding */\n",
    "                    background-color: #f4f4f4;\n",
    "                    color: #333;\n",
    "                    line-height: 1.6;\n",
    "                }\n",
    "                .container {\n",
    "                    width: 80%;\n",
    "                    margin: auto;\n",
    "                    overflow: hidden;\n",
    "                    padding-bottom: 120px; /* Additional padding to push content up */\n",
    "                }\n",
    "                h1, h2 {\n",
    "                    color: #0056b3;\n",
    "                }\n",
    "                h1 {\n",
    "                    font-size: 2.5em;\n",
    "                    margin-bottom: 10px;\n",
    "                }\n",
    "                h2 {\n",
    "                    font-size: 1.8em;\n",
    "                    margin-top: 30px;\n",
    "                }\n",
    "                p {\n",
    "                    font-size: 1.1em;\n",
    "                }\n",
    "                ul {\n",
    "                    list-style-type: none;\n",
    "                    padding: 0;\n",
    "                }\n",
    "                ul li {\n",
    "                    background: #e9ecef;\n",
    "                    padding: 10px;\n",
    "                    margin-bottom: 10px;\n",
    "                    border-radius: 5px;\n",
    "                }\n",
    "                ul li strong {\n",
    "                    color: #007bff;\n",
    "                }\n",
    "                footer {\n",
    "                    background-color: #333;\n",
    "                    color: #fff;\n",
    "                    text-align: center;\n",
    "                    padding: 10px;\n",
    "                    position: fixed;\n",
    "                    left: 0;\n",
    "                    bottom: 0;\n",
    "                    width: 100%;\n",
    "                }\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <div class=\"container\">\n",
    "                <h1>FraudSenseXAI</h1>\n",
    "                <h2>Overview</h2>\n",
    "                <p><strong>FraudSenseXAI</strong> is an innovative Machine Learning (ML) and Explainable Artificial Intelligence (XAI) application, developed as a part of an MSc final project by Othniel Obasi. This application is dedicated to detecting and analyzing fraudulent activities, with a strong emphasis on the interpretability and transparency of its AI models.</p>\n",
    "                <h2>Key Features</h2>\n",
    "                <ul>\n",
    "                    <li><strong>Robust Fraud Detection:</strong> Utilizes advanced ML techniques to identify fraudulent transactions accurately.</li>\n",
    "                    <li><strong>Explainable AI Elements:</strong> Employs XAI approaches to provide clear insights into the decision-making processes of the AI.</li>\n",
    "                    <li><strong>Interactive Web Interface:</strong> Features a user-friendly web application for easy access and interpretation of results.</li>\n",
    "                    <li><strong>Dynamic Visualizations:</strong> Integrates Plotly for interactive and insightful data visualizations.</li>\n",
    "                    <li><strong>Applicability Across Sectors:</strong> Suitable for use in finance, e-commerce, digital banking, and other sectors.</li>\n",
    "                </ul>\n",
    "                <h2>About the Author</h2>\n",
    "                <p>This project is an MSc Dissertation on the XAI Application of Fraud Detection, authored by Othniel Obasi. It represents a significant contribution to the field of AI, offering practical solutions and valuable insights for the detection of fraudulent activities using AI. For more information, visit the <a href=\"https://huggingface.co/spaces/Othniel74/XAIFraudSense\" target=\"_blank\">project page</a>  </p>\n",
    "                <h2>About the Author</h2>\n",
    "            </div>\n",
    "            <footer>\n",
    "                <p>FraudSenseXAI Â© 2024</p>\n",
    "            </footer>\n",
    "        </body>\n",
    "    </html>\n",
    "    \"\"\")\n",
    "\n",
    "# Endpoint to predict and explain\n",
    "@app.route('/predict_and_explain', methods=['POST'])\n",
    "def predict_and_explain():\n",
    "    try:\n",
    "        \n",
    "        data = request.get_json()\n",
    "        model_name = data['selected_model']\n",
    "        technique_name = data['selected_interpretability_method']\n",
    "        step = data['step']\n",
    "        transaction_type = data['transaction_type']\n",
    "        amount = data['amount']\n",
    "        oldbalanceOrg = data['oldbalanceOrg']\n",
    "        \n",
    "        \n",
    "\n",
    "        # Mapping transaction type to integer and preparing input data\n",
    "        transaction_type_num = 1 if transaction_type in [\"Transfer\", \"Cash Out\", \"Payment\", \"Cash In\"] else 0\n",
    "        user_data = {\n",
    "            'step': step,\n",
    "            'type': transaction_type_num,\n",
    "            'amount': amount,\n",
    "            'oldbalanceOrg': oldbalanceOrg,\n",
    "            'newbalanceOrig': oldbalanceOrg + amount\n",
    "        }\n",
    "        df = pd.DataFrame([user_data])\n",
    "        live_df = generate_transaction_features(df)\n",
    "\n",
    "        df = pd.DataFrame([user_data])\n",
    "        live_df = generate_transaction_features(df)\n",
    "        live_instance =  live_df\n",
    "        \n",
    "        pipeline, X_train, y_train = choose_model_and_data(model_name)\n",
    "        explainer = ModelExplainer(pipeline, live_df)\n",
    "        interpreter = LIMEModelInterpreter(pipeline, X_train, live_instance, model_name)\n",
    "        visualizer = SHAPVisualizer(pipeline, live_instance, X_train)\n",
    "        \n",
    "        \n",
    "        # Model selection\n",
    "        pipeline, X_train, y_train = choose_model_and_data(model_name)\n",
    "\n",
    "        # Making prediction\n",
    "        prediction = pipeline.predict(live_df)[0]\n",
    "        prediction_text = \"Fraudulent\" if prediction == 1 else \"Not Fraudulent\"\n",
    "        \n",
    "        lime_explanation, prediction = interpreter.limeExplainer_live()\n",
    "        feature_explanations = interpreter.lime_feature_extraction(lime_explanation)\n",
    "        mod_explanation, mod_plot, features_influence = choose_model_interpretability(technique_name, interpreter, visualizer, feature_explanations, prediction)\n",
    "        network_graph = plot_networkx_graph(model_name, technique_name, explainer)\n",
    "        network_explainer, top_main_effect, top_interaction = analyze_model_interactions(model_name, technique_name, explainer)\n",
    "\n",
    "        # Generate explanations and visualizations\n",
    "        cf_as_dict, original_instance = cf_explanations(pipeline, X_train, y_train, live_df, model_name, total_CFs=1)\n",
    "        lime_explanation = interpret_lime_results(pipeline, X_train, live_df, model_name)\n",
    "        radial_plot = visualize_counterfactuals_radar_plotly_v1(original_instance, cf_as_dict)\n",
    "        bar_chart = visualize_counterfactuals_plotly_v1(original_instance, cf_as_dict)\n",
    "        narrative = explain_counterfactual_percentage(original_instance, cf_as_dict)\n",
    "\n",
    "        # Convert plotly figures to JSON\n",
    "        radial_plot_json = convert_plotly_figure_to_json(radial_plot)\n",
    "        bar_chart_json = convert_plotly_figure_to_json(bar_chart)\n",
    "        mod_plot_json = convert_plotly_figure_to_json(mod_plot)\n",
    "\n",
    "\n",
    "        return jsonify({\n",
    "            'prediction_text': prediction_text,\n",
    "            'model_explanation': mod_explanation,\n",
    "            'features_influence': features_influence,\n",
    "            'lime_explanation': lime_explanation,\n",
    "            'radial_plot': radial_plot_json,\n",
    "            'network_graph':network_graph,\n",
    "            'network_explainer': network_explainer,\n",
    "            'top_main_effect': top_main_effect,\n",
    "            'top_interaction': top_interaction,            \n",
    "            'bar_chart': bar_chart_json,\n",
    "            'mod_plot': mod_plot_json,\n",
    "            'narrative': narrative\n",
    "        })\n",
    "    except Exception as e:\n",
    "        app.logger.error(\"Error in predict_and_explain: \" + str(e))\n",
    "        return jsonify({'error': 'An error occurred during processing.'}), 500\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set debug to False in a production environment\n",
    "    debug_mode = os.environ.get(\"DEBUG\", \"False\") == \"True\"\n",
    "    port = int(os.environ.get(\"PORT\", 5000))\n",
    "    app.run(host=\"0.0.0.0\", port=port, debug=debug_mode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac059b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dice_ml\n",
    "from dice_ml.utils import helpers \n",
    "from flask_cors import CORS\n",
    "from flask import send_file\n",
    "from dice_ml.utils.serialize import DummyDataInterface\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import plotly\n",
    "from dice_ml import Data, Model, Dice\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import pred_utils_v1\n",
    "from pred_utils_v1 import *\n",
    "import fraud_utils\n",
    "from fraud_utils import *\n",
    "import os\n",
    "from flask import Flask, render_template_string\n",
    "import ml_explainability_utils\n",
    "from ml_explainability_utils import *\n",
    "from ml_explainability_utils import LIMEModelInterpreter, ModelExplainer, SHAPVisualizer\n",
    "import base64\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load models and data outside of request context for efficiency\n",
    "try:\n",
    "    rfc_pipeline = joblib.load('rfc_adasyn_pipeline.pkl')\n",
    "    gbc_pipeline = joblib.load('gbc_smote_pipeline.pkl')\n",
    "    mlp_pipeline = joblib.load('mlp_smotetomek_pipeline.pkl')\n",
    "    X_train_ad, y_train_ad, X_train_smote, y_train_smote, X_train_stomek, y_train_stomek = get_data()\n",
    "except Exception as e:\n",
    "    app.logger.error(\"Failed to load models or data: \" + str(e))\n",
    "    # Consider whether to halt the app startup if critical resources fail to load\n",
    "\n",
    "# Utility function to convert plotly figures to JSON\n",
    "def convert_plotly_figure_to_json(fig):\n",
    "    return json.dumps(fig, cls=plotly.utils.PlotlyJSONEncoder)\n",
    "\n",
    "\n",
    "# Utility function to convert network graph to image\n",
    "def plot_networkx_graph_base64(model_name, technique_name, explainer):\n",
    "    image_path = None\n",
    "    base64_image = None\n",
    "    try:\n",
    "        # Determine the correct graph generation method based on the model and technique\n",
    "        if model_name == \"Random Forest\" and technique_name == \"SHAP\":\n",
    "            image_path = explainer.create_network_graph_with_communities_v1()\n",
    "        elif model_name == \"Gradient Boost\" and technique_name == \"SHAP\":\n",
    "            image_path = explainer.create_network_graph_with_communities_gbc_v1()\n",
    "        \n",
    "        # If an image path was generated, convert it to a base64 string\n",
    "        if image_path:\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "            # Prefix the base64 string with the necessary data URL scheme for direct use in HTML or Gradio interfaces\n",
    "            base64_image = f\"data:image/png;base64,{base64_image}\"\n",
    "\n",
    "    finally:\n",
    "        # Cleanup the image file if it exists\n",
    "        if image_path and os.path.exists(image_path):\n",
    "            os.remove(image_path)\n",
    "    \n",
    "    if base64_image:\n",
    "        return base64_image\n",
    "    else:\n",
    "        # Handle the case where no graph was generated\n",
    "        print(\"Network Graph Not Available.\")\n",
    "        return None\n",
    "            \n",
    "\n",
    "# Function to select the model interpretability technique- Options: LIME, \n",
    "def choose_model_interpretability(technique_name, interpreter, visualizer, feature_explanations, prediction):\n",
    "    if technique_name == 'LIME':\n",
    "        mod_explanation = interpreter.interpret_lime_results(feature_explanations, prediction)\n",
    "        mod_plot = interpreter.plot_lime_explanation(feature_explanations)\n",
    "        features_influence = interpreter.calculate_and_print_feature_influence(feature_explanations)\n",
    "    elif technique_name == 'SHAP':\n",
    "        mod_explanation = visualizer.shap_feature_influence_percentage()\n",
    "        mod_plot = visualizer.shap_exp_plot()\n",
    "        features_influence = visualizer.shap_feature_influence()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid technique name\")\n",
    "    return mod_explanation, mod_plot, features_influence\n",
    "\n",
    "\n",
    "# Utility function to analyze model interactions\n",
    "def analyze_model_interactions(model_name, technique_name, explainer):\n",
    "    # Initialize return variables to None as default\n",
    "     network_explainer, top_main_effect, top_interaction = None, None, None\n",
    "    \n",
    "    if model_name in [\"Random Forest\", \"Gradient Boost\"] and technique_name == \"SHAP\":\n",
    "        \n",
    "        if model_name == \"Random Forest\":\n",
    "            network_explainer = networkx_exp()  \n",
    "            top_main_effect, top_interaction = explainer.features_interaction()\n",
    "        elif model_name == \"Gradient Boost\":\n",
    "            network_explainer = networkx_exp()\n",
    "            top_main_effect, top_interaction = explainer.features_interaction_gbc()\n",
    "    else:\n",
    "        print(f\"For Feature Interactions Not Availbale for this Model.\")\n",
    "        return None, None, None \n",
    "\n",
    "    return network_explainer, top_main_effect, top_interaction\n",
    "\n",
    "\n",
    "\n",
    "# Function to select the model and corresponding training data based on name\n",
    "def choose_model_and_data(model_name):\n",
    "    if model_name == 'Random Forest':\n",
    "        pipeline = rfc_pipeline\n",
    "        X_train = X_train_ad\n",
    "        y_train = y_train_ad\n",
    "    elif model_name == 'Gradient Boost':\n",
    "        pipeline = gbc_pipeline\n",
    "        X_train = X_train_smote\n",
    "        y_train = y_train_smote\n",
    "    elif model_name == 'Neural Network':\n",
    "        pipeline = mlp_pipeline\n",
    "        X_train = X_train_stomek\n",
    "        y_train = y_train_stomek\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name\")\n",
    "    return pipeline, X_train, y_train\n",
    "\n",
    "\n",
    "# Endpoint to predict and explain\n",
    "@app.route('/predict_and_explain', methods=['POST'])\n",
    "def predict_and_explain():\n",
    "    try:\n",
    "        \n",
    "        data = request.get_json()\n",
    "        model_name = data['selected_model']\n",
    "        technique_name = data['selected_interpretability_method']\n",
    "        step = data['step']\n",
    "        transaction_type = data['transaction_type']\n",
    "        amount = data['amount']\n",
    "        oldbalanceOrg = data['oldbalanceOrg']\n",
    "        \n",
    "        \n",
    "\n",
    "        # Mapping transaction type to integer and preparing input data\n",
    "        transaction_type_num = 1 if transaction_type in [\"Transfer\", \"Cash Out\", \"Payment\", \"Cash In\"] else 0\n",
    "        user_data = {\n",
    "            'step': step,\n",
    "            'type': transaction_type_num,\n",
    "            'amount': amount,\n",
    "            'oldbalanceOrg': oldbalanceOrg,\n",
    "            'newbalanceOrig': oldbalanceOrg + amount\n",
    "        }\n",
    "        df = pd.DataFrame([user_data])\n",
    "        live_df = generate_transaction_features(df)\n",
    "\n",
    "        df = pd.DataFrame([user_data])\n",
    "        live_df = generate_transaction_features(df)\n",
    "        live_instance =  live_df\n",
    "        \n",
    "        pipeline, X_train, y_train = choose_model_and_data(model_name)\n",
    "        explainer = ModelExplainer(pipeline, live_df)\n",
    "        interpreter = LIMEModelInterpreter(pipeline, X_train, live_instance, model_name)\n",
    "        visualizer = SHAPVisualizer(pipeline, live_instance, X_train)\n",
    "        \n",
    "        \n",
    "        # Model selection\n",
    "        pipeline, X_train, y_train = choose_model_and_data(model_name)\n",
    "\n",
    "        # Making prediction\n",
    "        prediction = pipeline.predict(live_df)[0]\n",
    "        prediction_text = \"Fraudulent\" if prediction == 1 else \"Not Fraudulent\"\n",
    "        \n",
    "        lime_explanation, prediction = interpreter.limeExplainer_live()\n",
    "        feature_explanations = interpreter.lime_feature_extraction(lime_explanation)\n",
    "        mod_explanation, mod_plot, features_influence = choose_model_interpretability(technique_name, interpreter, visualizer, feature_explanations, prediction)\n",
    "        network_graph = plot_networkx_graph(model_name, technique_name, explainer)\n",
    "        network_explainer, top_main_effect, top_interaction = analyze_model_interactions(model_name, technique_name, explainer)\n",
    "\n",
    "        # Generate explanations and visualizations\n",
    "        cf_as_dict, original_instance = cf_explanations(pipeline, X_train, y_train, live_df, model_name, total_CFs=1)\n",
    "        lime_explanation = interpret_lime_results(pipeline, X_train, live_df, model_name)\n",
    "        radial_plot = visualize_counterfactuals_radar_plotly_v1(original_instance, cf_as_dict)\n",
    "        bar_chart = visualize_counterfactuals_plotly_v1(original_instance, cf_as_dict)\n",
    "        narrative = explain_counterfactual_percentage(original_instance, cf_as_dict)\n",
    "\n",
    "        # Convert plotly figures to JSON\n",
    "        mod_plot_json = convert_plotly_figure_to_json(mod_plot)       \n",
    "        radial_plot_json = convert_plotly_figure_to_json(radial_plot)\n",
    "        bar_chart_json = convert_plotly_figure_to_json(bar_chart)\n",
    " \n",
    "\n",
    "        return jsonify({\n",
    "            'prediction_text': prediction_text,\n",
    "            'model_explanation': mod_explanation,\n",
    "            'features_influence': features_influence,\n",
    "            'lime_explanation': lime_explanation,\n",
    "            'mod_plot': mod_plot_json,            \n",
    "            'network_graph':network_graph,\n",
    "            'network_explainer': network_explainer,\n",
    "            'top_main_effect': top_main_effect,\n",
    "            'top_interaction': top_interaction,\n",
    "            'radial_plot': radial_plot_json,            \n",
    "            'bar_chart': bar_chart_json,\n",
    "            'narrative': narrative\n",
    "        })\n",
    "    except Exception as e:\n",
    "        app.logger.error(\"Error in predict_and_explain: \" + str(e))\n",
    "        return jsonify({'error': 'An error occurred during processing.'}), 500\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set debug to False in a production environment\n",
    "    debug_mode = os.environ.get(\"DEBUG\", \"False\") == \"True\"\n",
    "    port = int(os.environ.get(\"PORT\", 5000))\n",
    "    app.run(host=\"0.0.0.0\", port=port, debug=debug_mode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab592b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "import json\n",
    "import plotly\n",
    "\n",
    "\n",
    "def predict_fraud(selected_model, selected_interpretability_method, step, transaction_type, amount, oldbalanceOrg):\n",
    "     # URL of the Flask API deployed on Heroku\n",
    "    url = \"https://xai-fraud-sense-7f7f4.herokuapp.com/predict_and_explain\" \n",
    "\n",
    "    # Prepare the data in the format expected by the Flask API\n",
    "    data = {\n",
    "        'selected_model': selected_model,\n",
    "        'selected_interpretability_method': selected_interpretability_method,\n",
    "        'step': step,\n",
    "        'transaction_type': transaction_type,\n",
    "        'amount': amount,\n",
    "        'oldbalanceOrg': oldbalanceOrg\n",
    "    }\n",
    "\n",
    "    # Send a POST request to the Flask API\n",
    "    response = requests.post(url, json=data)\n",
    "    if response.status_code == 200:\n",
    "        # Extract the response data\n",
    "        result = response.json()\n",
    "        prediction_text = result['prediction_text']\n",
    "        model_explanation = result['mod_explanation']\n",
    "        features_influence = result['features_influence']\n",
    "        lime_explanation = result['lime_explanation']\n",
    "        mod_plot_json = result['mod_plot']\n",
    "        \n",
    "        # Parse the JSON strings back into Plotly figures\n",
    "        mod_plot =  plotly.graph_objs.Figure(json.loads(mod_plot_json))\n",
    "        network_graph = result['network_graph']\n",
    "        network_explainer = result['network_explainer']\n",
    "        top_main_effect = result['top_main_effect']\n",
    "        top_interaction = result['top_interaction']                     \n",
    "        \n",
    "\n",
    "        # Parse the JSON strings back into Plotly figures\n",
    "        \n",
    "        radial_plot_json = result['radial_plot']\n",
    "        bar_chart_json = result['bar_chart']\n",
    "        radial_plot = plotly.graph_objs.Figure(json.loads(radial_plot_json))\n",
    "        bar_chart = plotly.graph_objs.Figure(json.loads(bar_chart_json))\n",
    "\n",
    "        narrative = result['narrative']\n",
    "\n",
    "        # Return the results\n",
    "        return prediction_text, model_explanation,features_influence, mod_plot, network_graph,network_explainer, top_main_effect,top_interaction, radial_plot, bar_chart,  narrative\n",
    "    else:\n",
    "        return \"Error: \" + response.text, None, None, None, None, None, None\n",
    "\n",
    "\n",
    "# Organizing inputs and outputs with enhanced styling\n",
    "with gr.Blocks() as iface:\n",
    "    gr.Markdown(\"<h2 style='text-align: center; font-weight: bold;'>FraudSenseXAI - Advanced Fraud Detection</h2>\")\n",
    "    gr.Markdown(\"<p style='text-align: center;'>Predict and analyze fraudulent transactions.</p>\", elem_id=\"description\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"#### Input Parameters\")\n",
    "            model_selection = gr.Dropdown(['Random Forest', 'Gradient Boost', 'Neural Network'], label=\"Model Selection\")\n",
    "            interpretability_selection = gr.Dropdown(['LIME', 'SHAP'], label=\"Interpretability Technique\")\n",
    "            step = gr.Number(value=1, label=\"Step\")\n",
    "            transaction_type = gr.Dropdown(['Transfer', 'Payment', 'Cash Out', 'Cash In'], label=\"Transaction Type\")\n",
    "            transaction_amount = gr.Number(label=\"Transaction Amount\")\n",
    "            old_balance_org = gr.Number(label=\"Old Balance Org\")\n",
    "            submit_button = gr.Button(\"Submit\", variant=\"primary\")\n",
    "            \n",
    "            prediction_text = gr.Text(label=\"Prediction\")\n",
    "            model_explanation = gr.Text(label=\"Model Explanation\", lines=7)         \n",
    "               \n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"#### Results and Interpretations\")\n",
    "                mod_plot = gr.Plot(label=\"Model Plot\")\n",
    "                features_influence = gr.Text(label=\"Features Influence\", lines=7)\n",
    "            \n",
    "            \n",
    "\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"#### Visualization\")\n",
    "            network_graph = gr.Image(label=\"Network Graph Plot\")\n",
    "            network_explainer = gr.Text(label=\"Network Explainer\", lines=7)\n",
    "            top_main_effect = gr.Text(label=\"Top Main Effect\", lines=7)\n",
    "            top_interaction = gr.Text(label=\"Top Interaction\", lines=7)            \n",
    "            radial_plot = gr.Plot(label=\"Radial Plot\")\n",
    "            bar_chart = gr.Plot(label=\"Bar Chart\")\n",
    "            narrative = gr.Text(label=\"Narrative\")  \n",
    "\n",
    "    submit_button.click(\n",
    "        predict_fraud, \n",
    "        inputs=[model_selection, interpretability_selection, step, transaction_type, transaction_amount, old_balance_org],\n",
    "        outputs=[prediction_text, model_explanation, mod_plot,features_influence, network_graph, network_explainer, top_main_effect, top_interaction, radial_plot, bar_chart, narrative]\n",
    "    )\n",
    "\n",
    "iface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbb9066",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "explainer = ModelExplainer(pipeline, live_df)\n",
    "\n",
    "# Utility function to convert network graph to image\n",
    "def plot_networkx_graph(model_name, technique_name, explainer):\n",
    "    image_path = None\n",
    "    try:\n",
    "        if model_name in [\"Random Forest\", \"Gradient Boost\"] and technique_name == \"SHAP\":\n",
    "            if model_name == \"Random Forest\":\n",
    "                image_path = explainer.create_network_graph_with_communities_v1()\n",
    "            elif model_name == \"Gradient Boost\":\n",
    "                image_path = explainer.create_network_graph_with_communities_gbc_v1()\n",
    "            else:\n",
    "                print(f\"Network Graph Not Available.\")\n",
    "                return None\n",
    "            return send_file(image_path, mimetype='image/png')\n",
    "    finally:\n",
    "        if image_path and os.path.exists(image_path):\n",
    "            os.remove(image_path)\n",
    "            \n",
    "\n",
    "network_graph = plot_networkx_graph(model_name, technique_name, explainer)\n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
